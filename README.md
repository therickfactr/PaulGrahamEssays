# Paul Graham Essays Explorer

A modern web application that allows users to explore and interact with Paul Graham's essays using natural language. Built with Next.js, TypeScript, and powered by OpenAI's GPT-4.

## Features

- ğŸ” Semantic search across Paul Graham's essay collection
- ğŸ’¬ Natural language chat interface for asking questions
- ğŸ“š Context-aware responses with source attribution
- ğŸ¨ Modern UI with responsive design
- ğŸ“± Mobile-friendly interface
- ğŸ“¥ Automated essay loading and processing

## Tech Stack

### Frontend (Explorer App)
- Next.js 14 with App Router
- TypeScript
- Tailwind CSS
- shadcn/ui components
- React Markdown with syntax highlighting

### Backend (API)
- Express.js
- TypeScript
- OpenAI GPT-4
- Supabase Vector Store
- LangChain

### Data Ingestion (Loader)
- Python
- BeautifulSoup4 for web scraping
- OpenAI embeddings
- Supabase integration
- Automated essay processing pipeline

## Project Structure

```
.
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ api/              # Express.js backend API
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ routes/   # API endpoints
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ chat.ts        # Chat endpoints
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ document.ts    # Document CRUD and search
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ health.ts      # Health check endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ services/ # Business logic
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ documentService.ts  # Document search and processing
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ llmService.ts       # LLM integration and response generation
â”‚   â”‚   â”‚   â”œâ”€â”€ types/    # TypeScript interfaces
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ chat.ts       # Chat-related types
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ document.ts   # Document-related types
â”‚   â”‚   â”‚   â””â”€â”€ lib/      # Utilities and configurations
â”‚   â”‚   â”‚       â”œâ”€â”€ supabase.ts   # Supabase client setup
â”‚   â”‚   â”‚       â””â”€â”€ vectorStore.ts # Vector store initialization
â”‚   â”‚   â””â”€â”€ package.json
â”‚   â”‚
â”‚   â””â”€â”€ explorer/         # Next.js frontend
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ app/      # Next.js app router
â”‚       â”‚   â”‚   â”œâ”€â”€ layout.tsx     # Root layout
â”‚       â”‚   â”‚   â””â”€â”€ page.tsx       # Main page
â”‚       â”‚   â”œâ”€â”€ components/ # React components
â”‚       â”‚   â”‚   â”œâ”€â”€ chat-interface.tsx  # Chat UI component
â”‚       â”‚   â”‚   â”œâ”€â”€ ui/            # Reusable UI components
â”‚       â”‚   â”‚   â””â”€â”€ ...            # Other components
â”‚       â”‚   â””â”€â”€ lib/      # Utilities
â”‚       â”‚       â””â”€â”€ api.ts         # API client configuration
â”‚       â””â”€â”€ package.json
â”‚
â”œâ”€â”€ loader/               # Python-based essay processing
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ loaders/     # Essay loading scripts
â”‚   â”‚   â”‚   â””â”€â”€ essay_loader.py    # Main essay loading script
â”‚   â”‚   â”œâ”€â”€ processors/  # Text processing utilities
â”‚   â”‚   â”‚   â””â”€â”€ text_processor.py  # Text cleaning and chunking
â”‚   â”‚   â””â”€â”€ utils/       # Helper functions
â”‚   â”‚       â””â”€â”€ supabase.py        # Supabase utilities
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ supabase/            # Database migrations and functions
â”‚   â”œâ”€â”€ migrations/      # SQL migrations
â”‚   â””â”€â”€ functions/       # Database functions
â”‚
â”œâ”€â”€ render.yaml          # Render.com deployment configuration
â””â”€â”€ package.json         # Root package.json for workspace
```

## Getting Started

### Prerequisites

- Node.js 18+
- Yarn
- Python 3.12+
- OpenAI API key
- Supabase account

### Local Development

1. Clone the repository:
   ```bash
   git clone <repository-url>
   cd PaulGrahamEssays
   ```

2. Install dependencies:
   ```bash
   # Install Node.js dependencies
   yarn install

   # Install Python dependencies
   cd loader
   pip install -r requirements.txt
   ```

3. Set up environment variables:
   - Create `.env` files in `apps/api`, `apps/explorer`, and `loader`
   - See `.env.example` files for required variables

4. Load the essays:
   ```bash
   cd loader
   python src/loaders/essay_loader.py
   ```

5. Start the development servers:
   ```bash
   # Start the API server
   cd apps/api
   yarn dev

   # Start the Explorer app
   cd apps/explorer
   yarn dev
   ```

6. Access the applications:
   - API: http://localhost:3081
   - Explorer: http://localhost:3000

## Data Processing

The Loader is a Python-based tool that:

1. Scrapes essays from paulgraham.com
2. Processes and cleans the text
3. Generates embeddings using OpenAI
4. Stores essays and embeddings in Supabase
5. Maintains metadata and relationships

### Key Features
- Automated essay discovery and loading
- Text cleaning and normalization
- Chunking for better search results
- Metadata extraction and storage
- Incremental updates for new essays

## Deployment

The project is configured for deployment on Render.com using the `render.yaml` file. The configuration includes:

- Separate services for API and Explorer app
- Automatic deployments from GitHub
- Health check endpoints
- Environment variable management

### Deployment Steps

1. Push your code to GitHub
2. Connect your repository to Render.com
3. Configure environment variables in the Render dashboard
4. Run the Loader to populate the database
5. Render will automatically deploy both services

## API Endpoints

### Health Check
- `GET /api/health` - Service health status

### Documents
- `GET /api/documents/search` - Search essays
- `POST /api/documents/chat` - Chat with the essay collection

## Suggested Prompts

Try these prompts to explore Paul Graham's essays:

- [What is a good founder?](docs/GOODFOUNDER.md)
- [What is an angel investor and what do they do?](docs/ANGELINVESTOR.md)
- [What kinds of work are there?](docs/KINDSOFWORK.md)
- [What is truth?](docs/TRUTH.md)
- [What makes a person stubborn?](docs/STUBBORN.md)
- [What is going on in Pittsburgh?](docs/PITTSBURGH.md)

Each prompt link leads to an example response that demonstrates the system's capabilities.

## Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- Paul Graham for his insightful [essays](https://www.paulgraham.com/articles.html)
- OpenAI for the GPT-4 model
- The open-source community for the amazing tools and libraries 
- [Bluebook Accounting](https://getbluebook.com) for the challenge! See [Requirements](./REQUIREMENTS.md)
